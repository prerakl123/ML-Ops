{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "26639b6e",
   "metadata": {},
   "source": [
    "## 1. Import libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3bc2f02b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import tensorflow as tf\n",
    "from keras import backend as K\n",
    "from keras.models import load_model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6ff102de",
   "metadata": {},
   "source": [
    "## 2. Loading model\n",
    "Load the pre-trained **YOLO** model using Darknet. Also load the model's configuration and weights files."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f190c7f9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the YOLO model\n",
    "model = cv2.dnn.readNetFromDarknet('cfg/yolov3.cfg', 'model/yolov3.weights')\n",
    "\n",
    "# Load the class names\n",
    "classes = []\n",
    "with open('model/coco.names', 'r') as f:\n",
    "    classes = [line.strip() for line in f.readlines()]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4605da31",
   "metadata": {},
   "source": [
    "## 3. Load image\n",
    "Load the image that we want to analyze"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d71066c7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the image\n",
    "img = cv2.imread(\"images/damaged_car.jpg\")\n",
    "\n",
    "# Convert the image to RGB format\n",
    "img = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b8a3fc12",
   "metadata": {},
   "source": [
    "## 4. Object  Detection\n",
    "Next, we use the YOLO model to detect objects and any damage to them."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c9af4879",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Resize the image\n",
    "image_size = (416, 416)\n",
    "img_resized = cv2.resize(img, image_size)\n",
    "\n",
    "# Convert the image to a blob\n",
    "blob = cv2.dnn.blobFromImage(img_resized, 1/255, image_size, [0, 0, 0], swapRB=True, crop=False)\n",
    "\n",
    "# Set the input of the model\n",
    "model.setInput(blob)\n",
    "\n",
    "# Forward pass through the model\n",
    "output_layers = model.getUnconnectedOutLayersNames()\n",
    "outs = model.forward(output_layers)\n",
    "\n",
    "# Extract the bounding boxes and classes\n",
    "boxes = []\n",
    "confidences = []\n",
    "class_ids = []\n",
    "for out in outs:\n",
    "    for detection in out:\n",
    "        scores = detection[5:]\n",
    "        class_id = np.argmax(scores)\n",
    "        confidence = scores[class_id]\n",
    "        if confidence > 0.5 and class_id == 0:\n",
    "            center_x = int(detection[0] * image_size[0])\n",
    "            center_y = int(detection[1] * image_size[1])\n",
    "            w = int(detection[2] * image_size[0])\n",
    "            h = int(detection[3] * image_size[1])\n",
    "            x = int(center_x - w / 2)\n",
    "            y = int(center_y - h / 2)\n",
    "            boxes.append([x, y, w, h])\n",
    "            confidences.append(float(confidence))\n",
    "            class_ids.append(class_id)\n",
    "\n",
    "# Perform non-maximum suppression\n",
    "nms_threshold = 0.5\n",
    "indices = cv2.dnn.NMSBoxes(boxes, confidences, 0.5, nms_threshold)\n",
    "\n",
    "# Display the image with the detected objects\n",
    "for i in indices:\n",
    "    i = i[0]\n",
    "    x, y, w, h = boxes[i]\n",
    "    cv2.rectangle(img_resized, (x, y), (x + w, y + h), (0, 0, 255), 2)\n",
    "\n",
    "plt.imshow(img_resized)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d81b45c1",
   "metadata": {},
   "source": [
    "## 5. Damage Analysis\n",
    "Once detected the damage to the object, analyze it by computing the area of the object by multiplying its width and height."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "50ecc172",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Compute the area of the detected object\n",
    "# x1, y1, x2, y2 = x, y, x + w, y + h\n",
    "# w = x2 - x1\n",
    "# h = y2 - y1\n",
    "# area = w * h\n",
    "# print('Area of damage:', area)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "import cv2\n",
    "\n",
    "# Load YOLOv3 model\n",
    "net = cv2.dnn.readNet('cfg/yolov3.cfg', 'model/yolov3.weights')\n",
    "\n",
    "# Load the image\n",
    "image = cv2.imread('images/most-congested-cities.jpg')\n",
    "\n",
    "# Get image dimensions\n",
    "height, width, _ = image.shape\n",
    "\n",
    "# Prepare the image for YOLO model\n",
    "blob = cv2.dnn.blobFromImage(image, 1/255.0, (416, 416), swapRB=True, crop=False)\n",
    "\n",
    "# Set the input to the neural network\n",
    "net.setInput(blob)\n",
    "\n",
    "# Get the names of the output layers\n",
    "output_layers = net.getUnconnectedOutLayersNames()\n",
    "\n",
    "# Forward pass to get the detected objects\n",
    "detections = net.forward(output_layers)\n",
    "# Define class labels\n",
    "class_labels = [ 'person', 'bicycle', 'car', 'motorbike', 'aeroplane', 'bus', 'train', 'truck', 'boat', 'traffic light',\n",
    "                 'fire hydrant', 'stop sign', 'parking meter', 'bench', 'bird', 'cat', 'dog', 'horse', 'sheep', 'cow',\n",
    "                 'elephant', 'bear', 'zebra', 'giraffe', 'backpack', 'umbrella', 'handbag', 'tie', 'suitcase', 'frisbee', \n",
    "                 'skis', 'snowboard', 'sports ball', 'kite', 'baseball bat', 'baseball glove', 'skateboard', 'surfboard', \n",
    "                 'tennis racket', 'bottle', 'wine glass', 'cup', 'fork', 'knife', 'spoon', 'bowl', 'banana', 'apple', \n",
    "                 'sandwich', 'orange', 'broccoli', 'carrot', 'hot dog', 'pizza', 'donut', 'cake', 'chair', 'sofa', \n",
    "                 'pottedplant', 'bed', 'diningtable', 'toilet', 'tvmonitor', 'laptop', 'mouse', 'remote', 'keyboard', \n",
    "                 'cell phone', 'microwave', 'oven', 'toaster', 'sink', 'refrigerator', 'book', 'clock', 'vase', 'scissors', \n",
    "                 'teddy bear', 'hair drier', 'toothbrush'\n",
    "]\n",
    "\n",
    "# Set confidence threshold\n",
    "confidence_threshold = 0.7\n",
    "\n",
    "# Process detections\n",
    "for detection in detections:\n",
    "    for obj in detection:\n",
    "        scores = obj[5:]\n",
    "        class_id = np.argmax(scores)\n",
    "        confidence = scores[class_id]\n",
    "\n",
    "        if confidence > confidence_threshold:\n",
    "            # Calculate bounding box coordinates\n",
    "            center_x, center_y, box_width, box_height = map(int, obj[0:4] * [width, height, width, height])\n",
    "            x, y = center_x - box_width // 2, center_y - box_height // 2\n",
    "\n",
    "            # Ensure class_id is within bounds of class_labels\n",
    "            if class_id < len(class_labels):\n",
    "                label = f'{class_labels[class_id]}: {confidence:.2f}'\n",
    "            else:\n",
    "                label = f'Unknown: {confidence:.2f}'\n",
    "\n",
    "            # Draw bounding box and label\n",
    "            cv2.rectangle(image, (x, y), (x + box_width, y + box_height), (0, 255, 0), 2)\n",
    "            cv2.putText(image, label, (x, y - 10), cv2.FONT_HERSHEY_SIMPLEX, 0.5, (0, 255, 0), 2)\n",
    "\n",
    "# Define the scale factor\n",
    "scale_factor = 0.8\n",
    "\n",
    "# Calculate the new dimensions for the scaled image\n",
    "new_width = int(image.shape[1] * scale_factor)\n",
    "new_height = int(image.shape[0] * scale_factor)\n",
    "\n",
    "# Resize the image with bounding boxes\n",
    "image_resized = cv2.resize(image, (new_width, new_height))\n",
    "\n",
    "# Display the scaled image with bounding boxes\n",
    "cv2.imshow('Scaled Object Detection', image_resized)\n",
    "cv2.waitKey(0)\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "bf86957e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "All videos in the folder have been played.\n"
     ]
    }
   ],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "import os\n",
    "\n",
    "cv2.dnn.DNN_BACKEND_CUDA = cv2.dnn.DNN_BACKEND_DEFAULT\n",
    "cv2.dnn.DNN_TARGET_CUDA = cv2.dnn.DNN_TARGET_CUDA_FP16\n",
    "\n",
    "# Load YOLOv3 model\n",
    "net = cv2.dnn.readNet('cfg/yolov3.cfg', 'model/yolov3.weights')\n",
    "\n",
    "# Define class labels and confidence threshold\n",
    "class_labels = [ 'person', 'bicycle', 'car', 'motorbike', 'aeroplane', 'bus', 'train', 'truck', 'boat', 'traffic light',\n",
    "                 'fire hydrant', 'stop sign', 'parking meter', 'bench', 'bird', 'cat', 'dog', 'horse', 'sheep', 'cow',\n",
    "                 'elephant', 'bear', 'zebra', 'giraffe', 'backpack', 'umbrella', 'handbag', 'tie', 'suitcase', 'frisbee', \n",
    "                 'skis', 'snowboard', 'sports ball', 'kite', 'baseball bat', 'baseball glove', 'skateboard', 'surfboard', \n",
    "                 'tennis racket', 'bottle', 'wine glass', 'cup', 'fork', 'knife', 'spoon', 'bowl', 'banana', 'apple', \n",
    "                 'sandwich', 'orange', 'broccoli', 'carrot', 'hot dog', 'pizza', 'donut', 'cake', 'chair', 'sofa', \n",
    "                 'pottedplant', 'bed', 'diningtable', 'toilet', 'tvmonitor', 'laptop', 'mouse', 'remote', 'keyboard', \n",
    "                 'cell phone', 'microwave', 'oven', 'toaster', 'sink', 'refrigerator', 'book', 'clock', 'vase', 'scissors', \n",
    "                 'teddy bear', 'hair drier', 'toothbrush'\n",
    "                ]\n",
    "confidence_threshold = 0.6\n",
    "\n",
    "# Define the scale factor (e.g., 0.5 for 50% scaling)\n",
    "scale_factor = 0.8\n",
    "\n",
    "# Get a list of video files in the \"videos\" folder\n",
    "video_folder = \"videos\"\n",
    "video_files = [os.path.join(video_folder, filename) for filename in os.listdir(video_folder) if filename.endswith(\".mp4\")]\n",
    "current_video_index = 0\n",
    "\n",
    "while current_video_index < len(video_files):\n",
    "    # Load the current video\n",
    "    video_file = video_files[current_video_index]\n",
    "    cap = cv2.VideoCapture(video_file)\n",
    "    if not cap.isOpened():\n",
    "        print(f\"Error: Could not open video file {video_file}\")\n",
    "        current_video_index += 1\n",
    "        continue\n",
    "\n",
    "    while True:\n",
    "        ret, frame = cap.read()\n",
    "        if not ret:\n",
    "            # End of video, move to the next video\n",
    "            break\n",
    "\n",
    "        # Resize the frame with bounding boxes\n",
    "        new_width = int(frame.shape[1] * scale_factor)\n",
    "        new_height = int(frame.shape[0] * scale_factor)\n",
    "        frame_resized = cv2.resize(frame, (new_width, new_height))\n",
    "\n",
    "        # Prepare the frame for YOLO model\n",
    "        blob = cv2.dnn.blobFromImage(frame_resized, 1/255.0, (416, 416), swapRB=True, crop=False)\n",
    "        net.setInput(blob)\n",
    "\n",
    "        # Get the names of the output layers\n",
    "        output_layers = net.getUnconnectedOutLayersNames()\n",
    "\n",
    "        # Forward pass to get the detected objects\n",
    "        detections = net.forward(output_layers)\n",
    "\n",
    "        # Process detections and draw bounding boxes\n",
    "        for detection in detections:\n",
    "            for obj in detection:\n",
    "                scores = obj[5:]\n",
    "                class_id = np.argmax(scores)\n",
    "                confidence = scores[class_id]\n",
    "\n",
    "                if confidence > confidence_threshold:\n",
    "                    # Calculate bounding box coordinates\n",
    "                    center_x, center_y, box_width, box_height = map(int, obj[0:4] * [new_width, new_height, new_width, new_height])\n",
    "                    x, y = center_x - box_width // 2, center_y - box_height // 2\n",
    "\n",
    "                    # Draw bounding box and label\n",
    "                    cv2.rectangle(frame_resized, (x, y), (x + box_width, y + box_height), (0, 255, 0), 2)\n",
    "                    label = f'{class_labels[class_id]}: {confidence:.2f}'\n",
    "                    cv2.putText(frame_resized, label, (x, y - 10), cv2.FONT_HERSHEY_SIMPLEX, 0.5, (0, 255, 0), 2)\n",
    "\n",
    "        # Display the scaled frame with bounding boxes\n",
    "        cv2.imshow('Object Detection', frame_resized)\n",
    "\n",
    "        key = cv2.waitKey(1) & 0xFF\n",
    "        if key == ord('q'):\n",
    "            break\n",
    "\n",
    "    cap.release()\n",
    "    cv2.destroyAllWindows()\n",
    "\n",
    "    # Move to the next video\n",
    "    current_video_index += 1\n",
    "\n",
    "# End of all videos in the folder\n",
    "print(\"All videos in the folder have been played.\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
